"""
API —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –¥–ª—è walk-forward –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π
"""
import pandas as pd
from fastapi import APIRouter, Depends, HTTPException, Query, BackgroundTasks
from typing import List, Dict, Any, Optional
from datetime import datetime
import logging
import asyncio

from backend.app.core import data_manager
from backend.app.core.validation.walk_forward import WalkForwardValidator, ValidationResults
from backend.app.core.xgboost_model import XGBoostLotteryModel
from backend.app.core.ai_model import RFModel, LotteryLSTMOps
from backend.app.core.lottery_context import LotteryContext
from backend.app.core.subscription_protection import require_premium
from backend.app.api.analysis import set_lottery_context
from backend.app.api.auth import get_current_user
from backend.app.core.database import get_db, SessionLocal
from backend.app.api.dashboard import DashboardService

router = APIRouter(prefix="/validation", tags=["Model Validation"])
logger = logging.getLogger(__name__)

# –•—Ä–∞–Ω–∏–ª–∏—â–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ë–î)
validation_cache = {}


@router.post("/walk-forward", summary="üî¨ Walk-forward –≤–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏")
async def run_walk_forward_validation(
    model_type: str = Query(..., regex="^(xgboost|rf|lstm)$", description="–¢–∏–ø –º–æ–¥–µ–ª–∏"),
    initial_train_size: int = Query(300, ge=100, le=1000, description="–ù–∞—á–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏"),
    test_size: int = Query(30, ge=10, le=100, description="–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –æ–∫–Ω–∞"),
    step_size: int = Query(30, ge=10, le=100, description="–®–∞–≥ —Å–¥–≤–∏–≥–∞ –æ–∫–Ω–∞"),
    expanding_window: bool = Query(True, description="–†–∞—Å—à–∏—Ä—è—é—â–µ–µ—Å—è –æ–∫–Ω–æ (True) –∏–ª–∏ —Å–∫–æ–ª—å–∑—è—â–µ–µ (False)"),
    background_tasks: BackgroundTasks = BackgroundTasks(),
    context: None = Depends(set_lottery_context),
    current_user = Depends(require_premium)
):
    """
    üîí –ü–†–ï–ú–ò–£–ú –§–£–ù–ö–¶–ò–Ø: Walk-forward –≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–ª—è —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏
    
    **–ß—Ç–æ —ç—Ç–æ –¥–∞—ë—Ç:**
    - –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –∏ lookahead bias
    - –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞ –±—É–¥—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
    - –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ –≤–æ –≤—Ä–µ–º–µ–Ω–∏
    - –í—ã—è–≤–ª–µ–Ω–∏–µ –¥–µ–≥—Ä–∞–¥–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏
    
    **–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**
    - model_type: –ö–∞–∫—É—é –º–æ–¥–µ–ª—å –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å (xgboost, rf, lstm)
    - initial_train_size: –ù–∞—á–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏
    - test_size: –†–∞–∑–º–µ—Ä –∫–∞–∂–¥–æ–≥–æ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –æ–∫–Ω–∞
    - step_size: –ù–∞ —Å–∫–æ–ª—å–∫–æ —Å–¥–≤–∏–≥–∞—Ç—å –æ–∫–Ω–æ
    - expanding_window: –†–∞—Å—à–∏—Ä—è—Ç—å –æ–∫–Ω–æ –æ–±—É—á–µ–Ω–∏—è –∏–ª–∏ —Å–¥–≤–∏–≥–∞—Ç—å
    
    **–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:** –ü—Ä–µ–º–∏—É–º –ø–æ–¥–ø–∏—Å–∫–∞
    """
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        df_history = data_manager.fetch_draws_from_db()
        
        if df_history.empty or len(df_history) < initial_train_size + test_size:
            raise HTTPException(
                status_code=404,
                detail=f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {len(df_history)} —Ç–∏—Ä–∞–∂–µ–π "
                      f"(–º–∏–Ω–∏–º—É–º {initial_train_size + test_size})"
            )
        
        config = data_manager.get_current_config()
        
        # –°–æ–∑–¥–∞–µ–º –≤–∞–ª–∏–¥–∞—Ç–æ—Ä
        validator = WalkForwardValidator(
            initial_train_size=initial_train_size,
            test_size=test_size,
            step_size=step_size,
            expanding_window=expanding_window
        )
        
        # –í—ã–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª—å
        if model_type == 'xgboost':
            from backend.app.core.xgboost_model import XGBoostLotteryModel
            model_class = XGBoostLotteryModel
            model_params = {}
        elif model_type == 'rf':
            model_class = RFModel
            model_params = {'n_estimators': 100}
        else:  # lstm
            model_class = LotteryLSTMOps
            model_params = {'n_steps_in': 5}
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –¥–ª—è –∑–∞–¥–∞—á–∏
        task_id = f"{model_type}_{data_manager.CURRENT_LOTTERY}_{datetime.now().timestamp()}"
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤ —Ñ–æ–Ω–µ
        background_tasks.add_task(
            run_validation_background,
            task_id, validator, model_class, model_params,
            df_history, config, current_user.id
        )
        
        return {
            'task_id': task_id,
            'status': 'started',
            'message': f'–í–∞–ª–∏–¥–∞—Ü–∏—è {model_type} –∑–∞–ø—É—â–µ–Ω–∞ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ',
            'estimated_time': estimate_validation_time(len(df_history), initial_train_size, test_size, step_size),
            'check_status_url': f'/api/v1/{data_manager.CURRENT_LOTTERY}/validation/status/{task_id}'
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/status/{task_id}", summary="üìä –°—Ç–∞—Ç—É—Å –≤–∞–ª–∏–¥–∞—Ü–∏–∏")
async def get_validation_status(
    task_id: str,
    context: None = Depends(set_lottery_context),
    current_user = Depends(get_current_user)
):
    """
    –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    
    **–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:**
    - –°—Ç–∞—Ç—É—Å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (running, completed, error)
    - –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –µ—Å–ª–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–æ
    - –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –µ—Å–ª–∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è
    """
    if task_id not in validation_cache:
        raise HTTPException(status_code=404, detail="–ó–∞–¥–∞—á–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    
    task_data = validation_cache[task_id]
    
    if task_data['status'] == 'completed':
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ–ª–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results = task_data['results']
        return {
            'task_id': task_id,
            'status': 'completed',
            'summary': results.get_summary(),
            'average_metrics': results.average_metrics,
            'std_metrics': results.std_metrics,
            'window_count': results.total_windows,
            'best_window': results.best_window,
            'worst_window': results.worst_window,
            'total_time': results.total_time,
            'window_details': [m.to_dict() for m in results.window_metrics[:10]]  # –ü–µ—Ä–≤—ã–µ 10 –æ–∫–æ–Ω
        }
    elif task_data['status'] == 'error':
        return {
            'task_id': task_id,
            'status': 'error',
            'error': task_data.get('error', 'Unknown error')
        }
    else:
        return {
            'task_id': task_id,
            'status': 'running',
            'progress': task_data.get('progress', 0),
            'message': task_data.get('message', '–í–∞–ª–∏–¥–∞—Ü–∏—è –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è...')
        }


@router.post("/compare", summary="‚öîÔ∏è –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π")
async def compare_models_validation(
    models: List[str] = Query(['xgboost', 'rf'], description="–ú–æ–¥–µ–ª–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"),
    initial_train_size: int = Query(200, ge=100, le=500),
    test_size: int = Query(20, ge=10, le=50),
    background_tasks: BackgroundTasks = BackgroundTasks(),
    context: None = Depends(set_lottery_context),
    current_user = Depends(require_premium)
):
    """
    üîí –ü–†–ï–ú–ò–£–ú –§–£–ù–ö–¶–ò–Ø: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ walk-forward –≤–∞–ª–∏–¥–∞—Ü–∏—é
    
    **–ß—Ç–æ –≤—ã –ø–æ–ª—É—á–∏—Ç–µ:**
    - –û–±—ä–µ–∫—Ç–∏–≤–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –Ω–∞ –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    - –í—ã—è–≤–ª–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –¥–ª—è –≤–∞—à–µ–π –ª–æ—Ç–µ—Ä–µ–∏
    - –ê–Ω–∞–ª–∏–∑ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
    
    **–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:** –ü—Ä–µ–º–∏—É–º –ø–æ–¥–ø–∏—Å–∫–∞
    """
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–æ–¥–µ–ª–∏
        valid_models = ['xgboost', 'rf', 'lstm']
        for model in models:
            if model not in valid_models:
                raise HTTPException(
                    status_code=400,
                    detail=f"–ù–µ–≤–µ—Ä–Ω–∞—è –º–æ–¥–µ–ª—å: {model}. –î–æ—Å—Ç—É–ø–Ω—ã: {valid_models}"
                )
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        df_history = data_manager.fetch_draws_from_db()
        
        if df_history.empty or len(df_history) < initial_train_size + test_size:
            raise HTTPException(
                status_code=404,
                detail=f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"
            )
        
        config = data_manager.get_current_config()
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º ID –∑–∞–¥–∞—á–∏
        task_id = f"compare_{data_manager.CURRENT_LOTTERY}_{datetime.now().timestamp()}"
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤ —Ñ–æ–Ω–µ
        background_tasks.add_task(
            run_comparison_background,
            task_id, models, initial_train_size, test_size,
            df_history, config, current_user.id
        )
        
        return {
            'task_id': task_id,
            'status': 'started',
            'models': models,
            'message': f'–°—Ä–∞–≤–Ω–µ–Ω–∏–µ {len(models)} –º–æ–¥–µ–ª–µ–π –∑–∞–ø—É—â–µ–Ω–æ',
            'check_status_url': f'/api/v1/{data_manager.CURRENT_LOTTERY}/validation/comparison/{task_id}'
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/comparison/{task_id}", summary="üìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")
async def get_comparison_results(
    task_id: str,
    context: None = Depends(set_lottery_context),
    current_user = Depends(get_current_user)
):
    """
    –ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π
    """
    if task_id not in validation_cache:
        raise HTTPException(status_code=404, detail="–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    
    task_data = validation_cache[task_id]
    
    if task_data['status'] == 'completed':
        return {
            'task_id': task_id,
            'status': 'completed',
            'comparison': task_data['comparison'],
            'winner': task_data['winner'],
            'ranking': task_data['ranking']
        }
    elif task_data['status'] == 'error':
        return {
            'task_id': task_id,
            'status': 'error',
            'error': task_data.get('error')
        }
    else:
        return {
            'task_id': task_id,
            'status': 'running',
            'progress': task_data.get('progress', 0),
            'current_model': task_data.get('current_model')
        }


@router.get("/history", summary="üìú –ò—Å—Ç–æ—Ä–∏—è –≤–∞–ª–∏–¥–∞—Ü–∏–π")
async def get_validation_history(
    limit: int = Query(10, ge=1, le=50),
    context: None = Depends(set_lottery_context),
    current_user = Depends(get_current_user)
):
    """
    –ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –≤–∞–ª–∏–¥–∞—Ü–∏–π
    """
    # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Ç–µ–∫—É—â–µ–π –ª–æ—Ç–µ—Ä–µ–µ –∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
    user_validations = [
        {
            'task_id': task_id,
            'status': data['status'],
            'model': data.get('model_type'),
            'started_at': data.get('started_at'),
            'completed_at': data.get('completed_at'),
            'summary': data['results'].get_summary() if data.get('results') else None
        }
        for task_id, data in validation_cache.items()
        if data.get('user_id') == current_user.id and 
           data.get('lottery_type') == data_manager.CURRENT_LOTTERY
    ]
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
    user_validations.sort(key=lambda x: x.get('started_at', ''), reverse=True)
    
    return {
        'validations': user_validations[:limit],
        'total': len(user_validations)
    }


# –§–æ–Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏

async def run_validation_background(task_id: str, validator: WalkForwardValidator,
                                   model_class: Any, model_params: Dict,
                                   df_history: pd.DataFrame, config: Dict,
                                   user_id: int):
    """–§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–∞–ø–∏—Å—å –≤ –∫—ç—à–µ
        validation_cache[task_id] = {
            'status': 'running',
            'progress': 0,
            'message': '–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏...',
            'started_at': datetime.now().isoformat(),
            'user_id': user_id,
            'lottery_type': data_manager.CURRENT_LOTTERY,
            'model_type': model_class.__name__
        }
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é
        logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏ {task_id}")
        
        results = validator.validate_model(
            model_class, model_params,
            df_history, config
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        validation_cache[task_id] = {
            'status': 'completed',
            'results': results,
            'completed_at': datetime.now().isoformat(),
            'user_id': user_id,
            'lottery_type': data_manager.CURRENT_LOTTERY,
            'model_type': model_class.__name__
        }
        
        # –õ–æ–≥–∏—Ä—É–µ–º –≤ –ë–î
        try:
            db = SessionLocal()
            dashboard_service = DashboardService(db)
            dashboard_service.log_activity(
                activity_type='validation_completed',
                description=f'Walk-forward –≤–∞–ª–∏–¥–∞—Ü–∏—è {model_class.__name__}: '
                          f'accuracy={results.average_metrics["accuracy"]:.3f}, '
                          f'f1={results.average_metrics["f1"]:.3f}',
                user_id=user_id,
                lottery_type=data_manager.CURRENT_LOTTERY,
                details={
                    'model': model_class.__name__,
                    'windows': results.total_windows,
                    'avg_accuracy': results.average_metrics['accuracy'],
                    'avg_f1': results.average_metrics['f1']
                }
            )
            db.close()
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        
        logger.info(f"‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è {task_id} –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ {task_id}: {e}")
        validation_cache[task_id] = {
            'status': 'error',
            'error': str(e),
            'user_id': user_id,
            'lottery_type': data_manager.CURRENT_LOTTERY
        }


async def run_comparison_background(task_id: str, models: List[str],
                                   initial_train_size: int, test_size: int,
                                   df_history: pd.DataFrame, config: Dict,
                                   user_id: int):
    """–§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π"""
    try:
        validation_cache[task_id] = {
            'status': 'running',
            'progress': 0,
            'current_model': None,
            'started_at': datetime.now().isoformat(),
            'user_id': user_id,
            'lottery_type': data_manager.CURRENT_LOTTERY
        }
        
        validator = WalkForwardValidator(
            initial_train_size=initial_train_size,
            test_size=test_size,
            step_size=test_size,
            expanding_window=True
        )
        
        model_configs = []
        for model_name in models:
            if model_name == 'xgboost':
                from backend.app.core.xgboost_model import XGBoostLotteryModel
                model_configs.append((XGBoostLotteryModel, {}))
            elif model_name == 'rf':
                model_configs.append((RFModel, {'n_estimators': 100}))
            elif model_name == 'lstm':
                model_configs.append((LotteryLSTMOps, {'n_steps_in': 5}))
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
        comparison_df = validator.compare_models(model_configs, df_history, config)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ–±–µ–¥–∏—Ç–µ–ª—è
        if 'avg_f1' in comparison_df.columns:
            winner_idx = comparison_df['avg_f1'].idxmax()
            winner = comparison_df.loc[winner_idx, 'model']
            ranking = comparison_df[['model', 'avg_accuracy', 'avg_f1']].to_dict('records')
        else:
            winner = 'Unknown'
            ranking = []
        
        validation_cache[task_id] = {
            'status': 'completed',
            'comparison': comparison_df.to_dict('records'),
            'winner': winner,
            'ranking': ranking,
            'completed_at': datetime.now().isoformat(),
            'user_id': user_id,
            'lottery_type': data_manager.CURRENT_LOTTERY
        }
        
        logger.info(f"‚úÖ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ {task_id} –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –ü–æ–±–µ–¥–∏—Ç–µ–ª—å: {winner}")
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è {task_id}: {e}")
        validation_cache[task_id] = {
            'status': 'error',
            'error': str(e),
            'user_id': user_id,
            'lottery_type': data_manager.CURRENT_LOTTERY
        }


def estimate_validation_time(data_size: int, train_size: int, 
                            test_size: int, step_size: int) -> float:
    """–û—Ü–µ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö"""
    # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–∫–æ–Ω
    num_windows = (data_size - train_size - test_size) // step_size + 1
    # –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è –Ω–∞ –æ–∫–Ω–æ (—Å–µ–∫—É–Ω–¥—ã)
    time_per_window = 2.0  # –ó–∞–≤–∏—Å–∏—Ç –æ—Ç –º–æ–¥–µ–ª–∏
    return num_windows * time_per_window
