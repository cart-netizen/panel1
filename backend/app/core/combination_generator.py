import random

import numpy as np
import pandas as pd
from collections import Counter
from backend.app.core.ai_model import GLOBAL_RF_MODEL  # Using the global RF model instance
from backend.app.core.pattern_analyzer import GLOBAL_PATTERN_ANALYZER
from backend.app.core.data_manager import get_current_config

from backend.app.core.xgboost_model import GLOBAL_XGBOOST_MANAGER


def generate_xgboost_ranked_combinations(df_history, num_to_generate, num_candidates=100):
  """
  –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–º–±–∏–Ω–∞—Ü–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º XGBoost —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è
  –ü—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç RF –ø–æ —Ç–æ—á–Ω–æ—Å—Ç–∏ –∏ —Å–∫–æ—Ä–æ—Å—Ç–∏

  Args:
      df_history: –ò—Å—Ç–æ—Ä–∏—è —Ç–∏—Ä–∞–∂–µ–π
      num_to_generate: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
      num_candidates: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏

  Returns:
      –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (field1, field2, –æ–ø–∏—Å–∞–Ω–∏–µ)
  """
  import time
  from backend.app.core.data_manager import get_current_config, CURRENT_LOTTERY

  if df_history.empty or len(df_history) < 10:
    print("XGBoost Gen: –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö.")
    return [(r1, r2, "–°–ª—É—á–∞–π–Ω–∞—è (–º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö)") for r1, r2 in
            [generate_random_combination() for _ in range(num_to_generate)]]

  print("üöÄ XGBoost –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å ML —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ–º...")
  start_time = time.time()

  # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏ –º–æ–¥–µ–ª—å
  config = get_current_config()
  xgb_model = GLOBAL_XGBOOST_MANAGER.get_model(CURRENT_LOTTERY, config)

  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—É—á–µ–Ω–∞ –ª–∏ –º–æ–¥–µ–ª—å
  if not xgb_model.is_trained:
    print("üéì XGBoost —Ç—Ä–µ–±—É–µ—Ç –æ–±—É—á–µ–Ω–∏—è...")
    train_start = time.time()
    success = xgb_model.train(df_history)

    if not success:
      print("‚ùå XGBoost –æ–±—É—á–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º RF fallback")
      return generate_rf_ranked_combinations(df_history, num_to_generate)

    print(f"‚úÖ XGBoost –æ–±—É—á–µ–Ω –∑–∞ {time.time() - train_start:.2f}—Å")

  # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
  candidates = []

  # 1. XGBoost –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
  last_draw = df_history.iloc[0]
  last_f1 = last_draw.get('–ß–∏—Å–ª–∞_–ü–æ–ª–µ1_list', [])
  last_f2 = last_draw.get('–ß–∏—Å–ª–∞_–ü–æ–ª–µ2_list', [])

  if isinstance(last_f1, list) and isinstance(last_f2, list):
    pred_f1, pred_f2 = xgb_model.predict_next_combination(last_f1, last_f2, df_history)
    if pred_f1 and pred_f2:
      candidates.append((pred_f1, pred_f2))

  # 2. –£–º–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
  from backend.app.core.trend_analyzer import GLOBAL_TREND_ANALYZER

  try:
    trends = GLOBAL_TREND_ANALYZER.analyze_current_trends(df_history)

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç—Ä–µ–Ω–¥–æ–≤
    for field_name, trend_data in trends.items():
      if field_name == 'field1':
        # –ö–æ–º–±–∏–Ω–∞—Ü–∏—è –≥–æ—Ä—è—á–∏—Ö —á–∏—Å–µ–ª —Å —É—Å–∫–æ—Ä–µ–Ω–∏–µ–º
        if trend_data.hot_acceleration:
          f1_hot = trend_data.hot_acceleration[:config['field1_size']]
          # –î–æ–ø–æ–ª–Ω—è–µ–º —Å–ª—É—á–∞–π–Ω—ã–º–∏ –µ—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç
          while len(f1_hot) < config['field1_size']:
            num = random.randint(1, config['field1_max'])
            if num not in f1_hot:
              f1_hot.append(num)

          f2_random = random.sample(range(1, config['field2_max'] + 1), config['field2_size'])
          candidates.append((sorted(f1_hot[:config['field1_size']]), sorted(f2_random)))

        # –ö–æ–º–±–∏–Ω–∞—Ü–∏—è —Ö–æ–ª–æ–¥–Ω—ã—Ö –≥–æ—Ç–æ–≤—ã—Ö –∫ —Ä–∞–∑–≤–æ—Ä–æ—Ç—É
        if trend_data.cold_reversal:
          f1_cold = trend_data.cold_reversal[:config['field1_size']]
          while len(f1_cold) < config['field1_size']:
            num = random.randint(1, config['field1_max'])
            if num not in f1_cold:
              f1_cold.append(num)

          f2_random = random.sample(range(1, config['field2_max'] + 1), config['field2_size'])
          candidates.append((sorted(f1_cold[:config['field1_size']]), sorted(f2_random)))

  except Exception as e:
    print(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤: {e}")

  # 3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —É–º–Ω—ã—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
  hot_f1, cold_f1 = analyze_hot_cold_numbers(df_history, 1)
  hot_f2, cold_f2 = analyze_hot_cold_numbers(df_history, 2)

  # –†–∞–∑–ª–∏—á–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
  strategies = [
    ('hot', hot_f1[:10], hot_f2[:10]),
    ('cold', cold_f1[:10], cold_f2[:10]),
    ('mixed', hot_f1[:5] + cold_f1[:5], hot_f2[:5] + cold_f2[:5])
  ]

  for strategy_name, pool_f1, pool_f2 in strategies:
    for _ in range(num_candidates // 3):
      if len(pool_f1) >= config['field1_size'] and len(pool_f2) >= config['field2_size']:
        f1 = sorted(random.sample(pool_f1, config['field1_size']))
        f2 = sorted(random.sample(pool_f2, config['field2_size']))
        candidates.append((f1, f2))

  # 4. –î–æ–ø–æ–ª–Ω—è–µ–º —Å–ª—É—á–∞–π–Ω—ã–º–∏ –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
  while len(candidates) < num_candidates:
    f1, f2 = generate_random_combination()
    candidates.append((f1, f2))

  # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
  unique_candidates = []
  seen = set()
  for f1, f2 in candidates:
    key = (tuple(f1), tuple(f2))
    if key not in seen:
      seen.add(key)
      unique_candidates.append((f1, f2))

  # –û—Ü–µ–Ω–∏–≤–∞–µ–º –≤—Å–µ –∫–∞–Ω–¥–∏–¥–∞—Ç—ã —á–µ—Ä–µ–∑ XGBoost
  print(f"‚ö° –û—Ü–µ–Ω–∫–∞ {len(unique_candidates)} –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ XGBoost...")
  scored_combinations = []

  for f1, f2 in unique_candidates:
    score = xgb_model.score_combination(f1, f2, df_history)
    scored_combinations.append((f1, f2, score))

  # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –æ—Ü–µ–Ω–∫–µ
  scored_combinations.sort(key=lambda x: x[2], reverse=True)

  # –ë–µ—Ä–µ–º —Ç–æ–ø –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏
  results = []
  for i, (f1, f2, score) in enumerate(scored_combinations[:num_to_generate]):
    # –ü–æ–ª—É—á–∞–µ–º SHAP –≤–∞–∂–Ω–æ—Å—Ç—å –¥–ª—è –ø–µ—Ä–≤–æ–π –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏
    importance_info = ""
    if i == 0:
      try:
        shap_data = xgb_model.get_shap_explanation(f1, f2, df_history)
        if 'top_important_features' in shap_data and shap_data['top_important_features']:
          top_feature = shap_data['top_important_features'][0]
          importance_info = f" [{top_feature['name']}]"
      except:
        pass

    desc = f"XGBoost #{i + 1} (score: {score:.1f}){importance_info}"
    results.append((f1, f2, desc))

  elapsed = time.time() - start_time
  print(f"‚úÖ XGBoost –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {elapsed:.2f}—Å")

  # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
  metrics = xgb_model.get_metrics()
  if metrics.get('roc_auc'):
    avg_auc = sum(metrics['roc_auc']) / len(metrics['roc_auc'])
    print(f"üìä XGBoost ROC-AUC: {avg_auc:.3f}, Cache hit: {metrics.get('cache_hit_rate', 0):.1f}%")

  return results


def generate_xgboost_prediction(df_history):
  """
  –ü–æ–ª—É—á–∏—Ç—å —á–∏—Å—Ç–æ–µ XGBoost –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ

  Returns:
      Tuple (field1, field2) –∏–ª–∏ (None, None)
  """
  from backend.app.core.data_manager import get_current_config, CURRENT_LOTTERY

  if df_history.empty or len(df_history) < 10:
    return None, None

  config = get_current_config()
  xgb_model = GLOBAL_XGBOOST_MANAGER.get_model(CURRENT_LOTTERY, config)

  if not xgb_model.is_trained:
    success = xgb_model.train(df_history)
    if not success:
      return None, None

  last_draw = df_history.iloc[0]
  last_f1 = last_draw.get('–ß–∏—Å–ª–∞_–ü–æ–ª–µ1_list', [])
  last_f2 = last_draw.get('–ß–∏—Å–ª–∞_–ü–æ–ª–µ2_list', [])

  if isinstance(last_f1, list) and isinstance(last_f2, list):
    return xgb_model.predict_next_combination(last_f1, last_f2, df_history)

  return None, None

def generate_random_combination():
  """
  –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–ª—É—á–∞–π–Ω—É—é –∫–æ–º–±–∏–Ω–∞—Ü–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ –¢–ï–ö–£–©–ï–ô –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –ª–æ—Ç–µ—Ä–µ–∏.
  """
  config = get_current_config()
  field1_size = config['field1_size']
  field2_size = config['field2_size']
  field1_max = config['field1_max']
  field2_max = config['field2_max']

  field1 = sorted(random.sample(range(1, field1_max + 1), field1_size))
  field2 = sorted(random.sample(range(1, field2_max + 1), field2_size))
  return field1, field2


def get_number_frequencies(df_history, field_column_name):
  """
    Calculates frequency of each number in a specified field from historical data.

    Args:
        df_history (pd.DataFrame): DataFrame with historical draws.
        field_column_name (str): Name of the column containing lists of numbers (e.g., '–ß–∏—Å–ª–∞_–ü–æ–ª–µ1_list').

    Returns:
        Counter: A Counter object with number frequencies.
    """
  frequency_counter = Counter()
  if not df_history.empty and field_column_name in df_history.columns:
    for numbers_list in df_history[field_column_name].dropna():
      if isinstance(numbers_list, list):
        frequency_counter.update(numbers_list)
  return frequency_counter


def generate_filtered_combination(df_history, filters=None):
  """
    Generates a random combination that satisfies a set of user-defined filters.
    This is a basic implementation; complex filter interactions can be challenging.

    Args:
        df_history (pd.DataFrame): Historical data, potentially for frequency-based filters.
        filters (dict, optional): A dictionary of filters. Example:
            {
                'sum_f1_min': 10, 'sum_f1_max': 70,
                'sum_f2_min': 10, 'sum_f2_max': 70,
                'parity_f1': {'even': 2, 'odd': 2}, # Exact count of even/odd in field 1
                'parity_f2': {'any': True}, # No parity filter for field 2
                'include_f1': [5, 10], # Must include these numbers in field 1
                'exclude_f1': [1, 20], # Must not include these numbers in field 1
                # Similar include/exclude for f2
                # 'hot_numbers_f1': 2, # Include N hottest numbers
                # 'cold_numbers_f1': 1 # Include N coldest numbers
            }

    Returns:
        tuple: (field1, field2) satisfying filters, or (None, None) if no combination
               found after max_attempts.
    """
  if filters is None:
    filters = {}
  max_attempts = 1000
  for attempt in range(max_attempts):
    f1, f2 = generate_random_combination()
    valid_f1 = True
    if 'sum_f1_min' in filters and sum(f1) < filters['sum_f1_min']: valid_f1 = False
    if valid_f1 and 'sum_f1_max' in filters and sum(f1) > filters['sum_f1_max']: valid_f1 = False
    if valid_f1 and 'parity_f1' in filters and not filters['parity_f1'].get('any', False):
      even_count = sum(1 for n in f1 if n % 2 == 0)
      odd_count = 4 - even_count
      if 'even' in filters['parity_f1'] and even_count != filters['parity_f1']['even']: valid_f1 = False
      if 'odd' in filters['parity_f1'] and odd_count != filters['parity_f1']['odd']: valid_f1 = False
    if valid_f1 and 'include_f1' in filters:
      if not all(num in f1 for num in filters['include_f1']): valid_f1 = False
    if valid_f1 and 'exclude_f1' in filters:
      if any(num in f1 for num in filters['exclude_f1']): valid_f1 = False
    valid_f2 = True
    if 'sum_f2_min' in filters and sum(f2) < filters['sum_f2_min']: valid_f2 = False
    if valid_f2 and 'sum_f2_max' in filters and sum(f2) > filters['sum_f2_max']: valid_f2 = False
    if valid_f2 and 'parity_f2' in filters and not filters['parity_f2'].get('any', False):
      even_count = sum(1 for n in f2 if n % 2 == 0)
      odd_count = 4 - even_count
      if 'even' in filters['parity_f2'] and even_count != filters['parity_f2']['even']: valid_f2 = False
      if 'odd' in filters['parity_f2'] and odd_count != filters['parity_f2']['odd']: valid_f2 = False
    if valid_f2 and 'include_f2' in filters:
      if not all(num in f2 for num in filters['include_f2']): valid_f2 = False
    if valid_f2 and 'exclude_f2' in filters:
      if any(num in f2 for num in filters['exclude_f2']): valid_f2 = False
    if valid_f1 and valid_f2:
      return f1, f2
  return None, None


def generate_ml_based_combinations(df_history, num_combinations=5):
  """
    Generates lottery combinations using the trained ML model and random generation.
    Aims to provide one "best guess" from the AI and supplement with random ones.

    Args:
        df_history (pd.DataFrame): DataFrame with historical draws, needed for training
                                   the model if not already trained, and for getting the last draw.
        num_combinations (int): Total number of combinations to generate.

    Returns:
        list: A list of tuples, where each tuple is (field1_list, field2_list, type_str).
              Example: [([1,2,3,4], [5,6,7,8], "AI Prediction"), ([...], [...], "Random")]
    """
  results = []
  config = get_current_config()
  if df_history.empty:
    print("ML Generator (simple): –ò—Å—Ç–æ—Ä–∏—è –ø—É—Å—Ç–∞. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π.")
    for _ in range(num_combinations):
      f1, f2 = generate_random_combination()
      results.append((f1, f2, "–°–ª—É—á–∞–π–Ω–∞—è (–ù–µ—Ç –ò—Å—Ç–æ—Ä–∏–∏)"))
    return results

  if not GLOBAL_RF_MODEL.is_trained:
    print("ML Generator (simple): –ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞. –ü–æ–ø—ã—Ç–∫–∞ –æ–±—É—á–µ–Ω–∏—è...")
    GLOBAL_RF_MODEL.train(df_history)
    if not GLOBAL_RF_MODEL.is_trained:
      print("ML Generator (simple): –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π.")
      for _ in range(num_combinations):
        f1, f2 = generate_random_combination()
        results.append((f1, f2, "–°–ª—É—á–∞–π–Ω–∞—è (–û—à–∏–±–∫–∞ AI)"))
      return results
    else:
      print("ML Generator (simple): –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞.")

  last_draw = df_history.iloc[0]
  last_f1 = last_draw.get('–ß–∏—Å–ª–∞_–ü–æ–ª–µ1_list')
  last_f2 = last_draw.get('–ß–∏—Å–ª–∞_–ü–æ–ª–µ2_list')

  if not (isinstance(last_f1, list) and len(last_f1) == 4 and
          isinstance(last_f2, list) and len(last_f2) == 4):
    print("ML Generator (simple): –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Ç–∏—Ä–∞–∂–∞. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö.")
    for _ in range(num_combinations):
      f1, f2 = generate_random_combination()
      results.append((f1, f2, "–°–ª—É—á–∞–π–Ω–∞—è (–ü–ª–æ—Ö–æ–π –ü–æ—Å–ª. –¢–∏—Ä–∞–∂)"))
    return results

  pred_f1, pred_f2 = GLOBAL_RF_MODEL.predict_next_combination(last_f1, last_f2)
  if pred_f1 and pred_f2 and len(pred_f1) == 4 and len(pred_f2) == 4:
    results.append((pred_f1, pred_f2, "AI –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ"))
  else:
    print("ML Generator (simple): AI –º–æ–¥–µ–ª—å –Ω–µ –¥–∞–ª–∞ –≤–∞–ª–∏–¥–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è. –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–ª—É—á–∞–π–Ω–æ–π –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏.")
    f1_rand_ai, f2_rand_ai = generate_random_combination()
    results.append((f1_rand_ai, f2_rand_ai, "–°–ª—É—á–∞–π–Ω–∞—è (–û—à–∏–±–∫–∞ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è AI)"))

  while len(results) < num_combinations:
    f1_rand, f2_rand = generate_random_combination()
    is_duplicate = False
    if results and pred_f1 and pred_f2:
      if sorted(f1_rand) == sorted(pred_f1) and sorted(f2_rand) == sorted(pred_f2):
        is_duplicate = True
    if not is_duplicate:
      results.append((f1_rand, f2_rand, "–°–ª—É—á–∞–π–Ω–∞—è"))
  return results[:num_combinations]


def generate_rf_ranked_combinations(df_history, num_to_generate, num_candidates_to_score=500):
  """
  –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º "—É–º–Ω–æ–≥–æ" –ø–æ–¥—Ö–æ–¥–∞ + –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤:
  1. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—É—â–∏–µ —Ç—Ä–µ–Ω–¥—ã –∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
  2. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç `num_candidates_to_score` —É–º–Ω—ã—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç—Ä–µ–Ω–¥–æ–≤
  3. –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞–∂–¥—É—é –∏–∑ –Ω–∏—Ö —Å –ø–æ–º–æ—â—å—é RF-–º–æ–¥–µ–ª–∏ (`score_combination`)
  4. –†–∞–Ω–∂–∏—Ä—É–µ—Ç –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –ø–æ –æ—Ü–µ–Ω–∫–µ —Å —É—á–µ—Ç–æ–º —Ç—Ä–µ–Ω–¥–æ–≤
  5. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ø `num_to_generate` –∫–æ–º–±–∏–Ω–∞—Ü–∏–π

  Args:
      df_history (pd.DataFrame): DataFrame —Å –∏—Å—Ç–æ—Ä–∏–µ–π —Ç–∏—Ä–∞–∂–µ–π.
      num_to_generate (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª—É—á—à–∏—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞.
      num_candidates_to_score (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª—É—á–∞–π–Ω—ã—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏ –æ—Ü–µ–Ω–∫–∏.

  Returns:
      list: –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (field1_list, field2_list, type_str_with_score).
  """
  import time
  from backend.app.core.data_cache import GLOBAL_DATA_CACHE
  from backend.app.core import data_manager
  from backend.app.core.rf_cache import GLOBAL_RF_CACHE

  results_with_scores = []

  if df_history.empty or len(df_history) < 2:
    print("RF Ranked Gen: –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö.")
    return [(r1, r2, "–°–ª—É—á–∞–π–Ω–∞—è (–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö)") for r1, r2 in
            [generate_random_combination() for _ in range(num_to_generate)]]

  print("‚ö° –ö–≠–®–ò–†–û–í–ê–ù–ù–ê–Ø –£–õ–¨–¢–†–ê –ë–´–°–¢–†–ê–Ø RF –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –∞–Ω–∞–ª–∏–∑–æ–º —Ç—Ä–µ–Ω–¥–æ–≤...")

  # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫—ç—à–∞
  cache_stats = GLOBAL_RF_CACHE.get_stats()
  print(f"üìä RF –∫—ç—à: {cache_stats['cache_size']} –∑–∞–ø–∏—Å–µ–π, hit rate: {cache_stats['hit_rate_percent']:.1f}%")

  # –û–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à –¥–∞–Ω–Ω—ã—Ö
  cached_df = GLOBAL_DATA_CACHE.get_cached_history(data_manager.CURRENT_LOTTERY)

  # –ù–û–í–û–ï: –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—É—â–∏—Ö —Ç—Ä–µ–Ω–¥–æ–≤
  print(f"üîç –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—É—â–∏—Ö —Ç—Ä–µ–Ω–¥–æ–≤...")
  trends_start = time.time()

  try:
    from backend.app.core.trend_analyzer import GLOBAL_TREND_ANALYZER, analyze_combination_with_trends
    current_trends = GLOBAL_TREND_ANALYZER.analyze_current_trends(df_history)
    trend_summary = GLOBAL_TREND_ANALYZER.get_trend_summary(current_trends)
    print(f"üìä –¢—Ä–µ–Ω–¥—ã ({time.time() - trends_start:.2f}—Å): {trend_summary}")
    use_trends = True
  except Exception as e:
    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤: {e}")
    current_trends = {}
    use_trends = False

  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –æ–±—É—á–∞–µ–º RF –º–æ–¥–µ–ª—å
  if not GLOBAL_RF_MODEL.is_trained:
    print("üéì RF –º–æ–¥–µ–ª—å —Ç—Ä–µ–±—É–µ—Ç –æ–±—É—á–µ–Ω–∏—è...")
    start_training = time.time()
    GLOBAL_RF_MODEL.train(df_history)
    training_time = time.time() - start_training

    if not GLOBAL_RF_MODEL.is_trained:
      print("‚ùå RF –æ–±—É—á–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å.")
      return [(r1, r2, "–°–ª—É—á–∞–π–Ω–∞—è (–æ—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è)") for r1, r2 in
              [generate_random_combination() for _ in range(num_to_generate)]]
    else:
      print(f"‚úÖ RF –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –∑–∞ {training_time:.1f}—Å")
  else:
    print("‚úÖ RF –º–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞")

  # –ê–î–ê–ü–¢–ò–í–ù–û–ï –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç—Ä–µ–±—É–µ–º–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
  if num_to_generate <= 1:
    candidates_count = max(6, num_to_generate * 4)  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
  elif num_to_generate <= 3:
    candidates_count = max(10, num_to_generate * 3)
  elif num_to_generate <= 5:
    candidates_count = max(15, num_to_generate * 3)
  else:
    candidates_count = min(num_candidates_to_score, max(20, num_to_generate * 2))

  print(f"‚ö° –ì–µ–Ω–µ—Ä–∞—Ü–∏—è {candidates_count} –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è {num_to_generate} –∏—Ç–æ–≥–æ–≤—ã—Ö...")

  start_time = time.time()
  max_time_seconds = 10.0  # –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –≤—Å–µ—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π

  try:
    from backend.app.core.parallel_rf import smart_combination_generator

    # –ù–û–í–û–ï: –£–º–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç—Ä–µ–Ω–¥–æ–≤
    if use_trends and current_trends:
      print(f"üéØ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å —É—á–µ—Ç–æ–º —Ç—Ä–µ–Ω–¥–æ–≤...")
      candidates = _generate_trend_aware_candidates(
        current_trends, candidates_count, num_to_generate
      )
    else:
      print(f"üîÑ –û–±—ã—á–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤...")
      candidates = smart_combination_generator(candidates_count, avoid_duplicates=True)

    # –ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å RF –æ—Ü–µ–Ω–∫–æ–π
    print(f"‚ö° –ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ {len(candidates)} –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤")
    scored_combinations = []

    eval_start = time.time()
    cache_hits = 0

    for i, (f1, f2) in enumerate(candidates):
      if time.time() - start_time > max_time_seconds:
        print(f"‚è∞ –¢–∞–π–º–∞—É—Ç {max_time_seconds}—Å –Ω–∞ {i}/{len(candidates)}")
        break

      # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à –ü–ï–†–ï–î –æ—Ü–µ–Ω–∫–æ–π
      cached_score = GLOBAL_RF_CACHE.get_score(f1, f2)
      if cached_score is not None:
        cache_hits += 1
        rf_score = cached_score
      else:
        # RF –æ—Ü–µ–Ω–∫–∞ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ—Ç –≤ –∫—ç—à–µ
        rf_score = GLOBAL_RF_MODEL.score_combination(sorted(f1), sorted(f2), cached_df)

      # –ù–û–í–û–ï: –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ RF + —Ç—Ä–µ–Ω–¥—ã
      if use_trends and current_trends:
        trend_score, trend_desc = analyze_combination_with_trends(f1, f2, df_history)
        # –í–∑–≤–µ—à–µ–Ω–Ω–∞—è –∫–æ–º–±–∏–Ω–∞—Ü–∏—è: 70% RF, 30% —Ç—Ä–µ–Ω–¥—ã
        combined_score = rf_score * 0.7 + (trend_score * 100) * 0.3
        score_desc = f"RF+—Ç—Ä–µ–Ω–¥"
      else:
        combined_score = rf_score
        score_desc = "RF"

      scored_combinations.append((f1, f2, combined_score, score_desc))

    eval_time = time.time() - eval_start
    rate = len(scored_combinations) / eval_time if eval_time > 0 else 0
    print(f"‚ö° –ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞: {len(scored_combinations)} –∑–∞ {eval_time:.1f}—Å (—Å–∫–æ—Ä–æ—Å—Ç—å: {rate:.1f}/—Å)")
    print(f"üìä –ö—ç—à —Ö–∏—Ç—ã: {cache_hits}/{len(scored_combinations)} ({cache_hits / len(scored_combinations) * 100:.1f}%)")

    # –ë—ã—Å—Ç—Ä–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≤–∞–ª–∏–¥–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    results_with_scores = [
      {'f1': f1, 'f2': f2, 'score': score, 'desc': desc}
      for f1, f2, score, desc in scored_combinations
      if score > -float('inf')
    ]

    print(f"üìä –í–∞–ª–∏–¥–Ω—ã—Ö: {len(results_with_scores)} –∏–∑ {len(scored_combinations)}")

  except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
    import traceback
    traceback.print_exc()

    # –°—É–ø–µ—Ä –±—ã—Å—Ç—Ä—ã–π fallback
    print("üîÑ Fallback –∫ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏...")
    for i in range(min(3, num_to_generate)):
      if time.time() - start_time > max_time_seconds:
        break
      f1, f2 = generate_random_combination()
      score = GLOBAL_RF_MODEL.score_combination(sorted(f1), sorted(f2), cached_df)
      if score > -float('inf'):
        results_with_scores.append({'f1': f1, 'f2': f2, 'score': score, 'desc': 'fallback'})

  if not results_with_scores:
    print("‚ùå –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö.")
    return [(r1, r2, "–°–ª—É—á–∞–π–Ω–∞—è (–Ω–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤)") for r1, r2 in
            [generate_random_combination() for _ in range(num_to_generate)]]

  # –ë—ã—Å—Ç—Ä–∞—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –æ—Ü–µ–Ω–∫–µ
  ranked_results = sorted(results_with_scores, key=lambda x: x['score'], reverse=True)

  # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –æ–ø–∏—Å–∞–Ω–∏—è–º–∏
  final_combinations = []
  for i in range(min(num_to_generate, len(ranked_results))):
    res = ranked_results[i]
    score_display = f"{res['score']:.1f}"
    rank_suffix = "ü•á" if i == 0 else "ü•à" if i == 1 else "ü•â" if i == 2 else f"#{i + 1}"

    # –ù–û–í–û–ï: –£–ª—É—á—à–µ–Ω–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å —Ç—Ä–µ–Ω–¥–∞–º–∏
    if use_trends and current_trends:
      trend_info = ""
      # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç—Ä–µ–Ω–¥–∞–º
      field1_trends = current_trends['field1'] if 'field1' in current_trends else None
      field2_trends = current_trends['field2'] if 'field2' in current_trends else None

      if field1_trends:
        hot_match = len(set(res['f1']) & set(field1_trends.hot_acceleration))
        momentum_match = len(set(res['f1']) & set(field1_trends.momentum_numbers))
        if hot_match > 0 or momentum_match > 0:
          trend_info = f" üî•H{hot_match}‚ö°M{momentum_match}"

      description = f"‚ö°{res['desc']} {rank_suffix}{trend_info} ({score_display})"
    else:
      description = f"‚ö°Cache {rank_suffix} ({score_display})"

    final_combinations.append((res['f1'], res['f2'], description))

  # –î–æ–ø–æ–ª–Ω–µ–Ω–∏–µ —Å–ª—É—á–∞–π–Ω—ã–º–∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
  while len(final_combinations) < num_to_generate:
    f1_rand, f2_rand = generate_random_combination()
    final_combinations.append((f1_rand, f2_rand, "–°–ª—É—á–∞–π–Ω–∞—è"))

  elapsed_total = time.time() - start_time
  efficiency = len(results_with_scores) / elapsed_total if elapsed_total > 0 else 0

  # –ù–û–í–û–ï: –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
  trend_suffix = " —Å —Ç—Ä–µ–Ω–¥–∞–º–∏" if use_trends else ""
  print(f"‚ö° –ö–≠–®–ò–†–û–í–ê–ù–ù–ê–Ø –°–ö–û–†–û–°–¢–¨{trend_suffix}: {elapsed_total:.1f}—Å, —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {efficiency:.1f}/—Å")

  if use_trends and current_trends:
    field1_strength = current_trends['field1'].trend_strength if 'field1' in current_trends else 0
    field2_strength = current_trends['field2'].trend_strength if 'field2' in current_trends else 0
    print(f"üéØ –ö–∞—á–µ—Å—Ç–≤–æ —Ç—Ä–µ–Ω–¥–æ–≤: –ü–æ–ª–µ1 —Å–∏–ª–∞={field1_strength:.2f}, –ü–æ–ª–µ2 —Å–∏–ª–∞={field2_strength:.2f}")

  return final_combinations

def _generate_trend_aware_candidates(trends, total_candidates, target_results):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ —Å —É—á–µ—Ç–æ–º —Ç–µ–∫—É—â–∏—Ö —Ç—Ä–µ–Ω–¥–æ–≤

    Args:
        trends: –°–ª–æ–≤–∞—Ä—å —Å —Ç—Ä–µ–Ω–¥–∞–º–∏ –æ—Ç GLOBAL_TREND_ANALYZER
        total_candidates: –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
        target_results: –¶–µ–ª–µ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

    Returns:
        List[Tuple]: –°–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (f1, f2)
    """
    candidates = []

    # –ü–æ–ª—É—á–∞–µ–º —Ç—Ä–µ–Ω–¥—ã –¥–ª—è –ø–æ–ª–µ–π
    field1_trends = trends['field1'] if 'field1' in trends else None
    field2_trends = trends['field2'] if 'field2' in trends else None

    # 40% –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ - –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥–æ—Ä—è—á–∏—Ö —á–∏—Å–µ–ª –∏ –∏–º–ø—É–ª—å—Å–∞
    trend_candidates = min(total_candidates * 4 // 10, target_results * 3)

    for _ in range(trend_candidates):
      try:
        f1 = _generate_smart_field_combination(field1_trends, 1)
        f2 = _generate_smart_field_combination(field2_trends, 2)
        candidates.append((f1, f2))
      except Exception:
        # Fallback –Ω–∞ —Å–ª—É—á–∞–π–Ω—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
        f1, f2 = generate_random_combination()
        candidates.append((f1, f2))

    # 30% –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ - —Å–º–µ—à–∞–Ω–Ω—ã–µ
    mixed_candidates = min(total_candidates * 3 // 10, target_results * 2)

    for _ in range(mixed_candidates):
      try:
        # –û–¥–Ω–æ –ø–æ–ª–µ - —Ç—Ä–µ–Ω–¥, –¥—Ä—É–≥–æ–µ - —Å–ª—É—á–∞–π–Ω–æ–µ
        if random.choice([True, False]):
          f1 = _generate_smart_field_combination(field1_trends, 1)
          f2 = _generate_random_field(2)
        else:
          f1 = _generate_random_field(1)
          f2 = _generate_smart_field_combination(field2_trends, 2)
        candidates.append((f1, f2))
      except Exception:
        f1, f2 = generate_random_combination()
        candidates.append((f1, f2))

    # –û—Å—Ç–∞–ª—å–Ω—ã–µ 30% - —Å–ª—É—á–∞–π–Ω—ã–µ
    remaining = total_candidates - len(candidates)
    for _ in range(remaining):
      f1, f2 = generate_random_combination()
      candidates.append((f1, f2))

    return candidates[:total_candidates]


def _generate_random_field(field_num):
  """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–ª—É—á–∞–π–Ω–æ–µ –ø–æ–ª–µ"""
  from backend.app.core import data_manager
  config = data_manager.get_current_config()
  field_size = config[f'field{field_num}_size']
  max_num = config[f'field{field_num}_max']
  return sorted(random.sample(range(1, max_num + 1), field_size))


def _generate_smart_field_combination(field_trends, field_num):
  """
  –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–º–Ω—É—é –∫–æ–º–±–∏–Ω–∞—Ü–∏—é –¥–ª—è –ø–æ–ª—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç—Ä–µ–Ω–¥–æ–≤

  Args:
      field_trends: TrendMetrics –¥–ª—è –ø–æ–ª—è
      field_num: –ù–æ–º–µ—Ä –ø–æ–ª—è (1 –∏–ª–∏ 2)

  Returns:
      List[int]: –ö–æ–º–±–∏–Ω–∞—Ü–∏—è —á–∏—Å–µ–ª –¥–ª—è –ø–æ–ª—è
  """
  from backend.app.core import data_manager
  config = data_manager.get_current_config()
  field_size = config[f'field{field_num}_size']
  max_num = config[f'field{field_num}_max']

  if not field_trends:
    # Fallback –Ω–∞ —Å–ª—É—á–∞–π–Ω—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
    return sorted(random.sample(range(1, max_num + 1), field_size))

  result = []
  all_numbers = list(range(1, max_num + 1))

  # 50% - –≥–æ—Ä—è—á–∏–µ —á–∏—Å–ª–∞
  hot_count = min(len(field_trends.hot_acceleration), field_size // 2)
  if hot_count > 0:
    result.extend(field_trends.hot_acceleration[:hot_count])

  # 25% - —á–∏—Å–ª–∞ —Å –∏–º–ø—É–ª—å—Å–æ–º
  momentum_count = min(len(field_trends.momentum_numbers), field_size // 4)
  if momentum_count > 0:
    momentum_to_add = [n for n in field_trends.momentum_numbers[:momentum_count] if n not in result]
    result.extend(momentum_to_add[:momentum_count])

  # –î–æ–ø–æ–ª–Ω—è–µ–º —Å–ª—É—á–∞–π–Ω—ã–º–∏
  remaining = field_size - len(result)
  if remaining > 0:
    available = [n for n in all_numbers if n not in result]
    if len(available) >= remaining:
      result.extend(random.sample(available, remaining))
    else:
      result.extend(available)
      # –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç, –∑–∞–ø–æ–ª–Ω—è–µ–º –ª—é–±—ã–º–∏ –¥–æ—Å—Ç—É–ø–Ω—ã–º–∏
      while len(result) < field_size:
        result.append(random.randint(1, max_num))

  return sorted(result[:field_size])


def _generate_random_field_combination(field_num):
  """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–ª—É—á–∞–π–Ω—É—é –∫–æ–º–±–∏–Ω–∞—Ü–∏—é –¥–ª—è –ø–æ–ª—è"""
  from backend.app.core.data_manager import get_current_config
  import random

  config = get_current_config()
  field_size = config[f'field{field_num}_size']
  field_max = config[f'field{field_num}_max']

  return sorted(random.sample(range(1, field_max + 1), field_size))


def generate_pattern_based_combinations(df_history, num_to_generate, strategy='balanced'):
  """
  –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤.
  –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –≥–æ—Ä—è—á–∏–µ/—Ö–æ–ª–æ–¥–Ω—ã–µ —á–∏—Å–ª–∞, –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –∏ —Ü–∏–∫–ª—ã.

  Args:
      df_history: DataFrame —Å –∏—Å—Ç–æ—Ä–∏–µ–π
      num_to_generate: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–±–∏–Ω–∞—Ü–∏–π
      strategy: 'hot' (–≥–æ—Ä—è—á–∏–µ), 'cold' (—Ö–æ–ª–æ–¥–Ω—ã–µ), 'balanced' (—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ),
               'correlated' (—Å —É—á–µ—Ç–æ–º –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π), 'overdue' (–ø—Ä–æ—Å—Ä–æ—á–µ–Ω–Ω—ã–µ)

  Returns:
      list: –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (field1, field2, –æ–ø–∏—Å–∞–Ω–∏–µ)
  """
  if df_history.empty:
    print("Pattern Generator: –ò—Å—Ç–æ—Ä–∏—è –ø—É—Å—Ç–∞. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π.")
    return [(f1, f2, "–°–ª—É—á–∞–π–Ω–∞—è (–Ω–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏)") for f1, f2 in
            [generate_random_combination() for _ in range(num_to_generate)]]

  # --- –ì–õ–ê–í–ù–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü–û–õ–£–ß–ê–ï–ú –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Æ ---
  config = get_current_config()
  f1_size = config['field1_size']
  f2_size = config['field2_size']
  f1_max = config['field1_max']
  f2_max = config['field2_max']

  results = []

  hot_cold = GLOBAL_PATTERN_ANALYZER.analyze_hot_cold_numbers(df_history, window_sizes=[20], top_n=10)
  correlations = GLOBAL_PATTERN_ANALYZER.find_number_correlations(df_history)
  cycles = GLOBAL_PATTERN_ANALYZER.analyze_draw_cycles(df_history)

  field1_data = hot_cold.get('field1_window20', {})
  field2_data = hot_cold.get('field2_window20', {})

  field1_hot = [n[0] for n in field1_data.get('hot_numbers', [])]
  field1_cold = [n[0] for n in field1_data.get('cold_numbers', [])]
  field2_hot = [n[0] for n in field2_data.get('hot_numbers', [])]
  field2_cold = [n[0] for n in field2_data.get('cold_numbers', [])]

  field1_pairs = correlations.get('field1', {}).get('frequent_pairs', [])
  field2_pairs = correlations.get('field2', {}).get('frequent_pairs', [])

  field1_cycles = cycles.get('field1', {})
  field2_cycles = cycles.get('field2', {})
  field1_overdue = [num for num, data in field1_cycles.items() if data.get('overdue', False)]
  field2_overdue = [num for num, data in field2_cycles.items() if data.get('overdue', False)]

  all_numbers_f1 = list(range(1, f1_max + 1))
  all_numbers_f2 = list(range(1, f2_max + 1))

  for i in range(num_to_generate):
    # --- –ò–°–ü–û–õ–¨–ó–£–ï–ú –î–ò–ù–ê–ú–ò–ß–ï–°–ö–ò–ï –†–ê–ó–ú–ï–†–´ –ü–û–õ–ï–ô –í–ú–ï–°–¢–û '4' ---
    if strategy == 'hot':
      f1 = _generate_with_preference(field1_hot, all_numbers_f1, f1_size, min_preferred=2)
      f2 = _generate_with_preference(field2_hot, all_numbers_f2, f2_size, min_preferred=1 if f2_size < 3 else 2)
      desc = "–ì–æ—Ä—è—á–∏–µ —á–∏—Å–ª–∞"
    elif strategy == 'cold':
      f1 = _generate_with_preference(field1_cold, all_numbers_f1, f1_size, min_preferred=2)
      f2 = _generate_with_preference(field2_cold, all_numbers_f2, f2_size, min_preferred=1 if f2_size < 3 else 2)
      desc = "–•–æ–ª–æ–¥–Ω—ã–µ —á–∏—Å–ª–∞"
    elif strategy == 'balanced':
      f1 = _generate_balanced(field1_hot, field1_cold, all_numbers_f1, f1_size)
      f2 = _generate_balanced(field2_hot, field2_cold, all_numbers_f2, f2_size)
      desc = "–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è (–≥–æ—Ä—è—á–∏–µ+—Ö–æ–ª–æ–¥–Ω—ã–µ)"
    elif strategy == 'correlated':
      f1 = _generate_with_correlations(field1_pairs, all_numbers_f1, f1_size)
      f2 = _generate_with_correlations(field2_pairs, all_numbers_f2, f2_size)
      desc = "–ö–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä—ã"
    elif strategy == 'overdue':
      f1 = _generate_with_preference(field1_overdue, all_numbers_f1, f1_size, min_preferred=1)
      f2 = _generate_with_preference(field2_overdue, all_numbers_f2, f2_size, min_preferred=1)
      desc = "–ü—Ä–æ—Å—Ä–æ—á–µ–Ω–Ω—ã–µ —á–∏—Å–ª–∞"
    else:
      f1, f2 = generate_random_combination()
      desc = "–°–ª—É—á–∞–π–Ω–∞—è"

    results.append((sorted(f1), sorted(f2), desc))

  return results


def _generate_with_preference(preferred_numbers, all_numbers, count, min_preferred=1):
  """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ–º–±–∏–Ω–∞—Ü–∏—é —Å –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–µ–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö —á–∏—Å–µ–ª"""
  result = []
  available = list(all_numbers)

  if not preferred_numbers:
    # –ï—Å–ª–∏ –Ω–µ—Ç –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º—ã—Ö —á–∏—Å–µ–ª, –ø—Ä–æ—Å—Ç–æ –±–µ—Ä–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ
    return random.sample(available, count)

  preferred_available = [n for n in preferred_numbers if n in available]
  num_to_take = min(min_preferred, len(preferred_available), count)

  if preferred_available and num_to_take > 0:
    selected = random.sample(preferred_available, num_to_take)
    result.extend(selected)
    for n in selected:
      available.remove(n)

  remaining = count - len(result)
  if remaining > 0:
    if not available:  # –ù–∞ —Å–ª—É—á–∞–π –µ—Å–ª–∏ preferred_numbers —Å–æ–¥–µ—Ä–∂–∞–ª–∏ –≤—Å–µ —á–∏—Å–ª–∞
      # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∏ —É–¥–∞–ª–∏–º —É–∂–µ –≤—ã–±—Ä–∞–Ω–Ω—ã–µ
      available = list(all_numbers)
      available = [n for n in available if n not in result]

    # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ
    if len(available) < remaining:
      # –ï—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç, –¥–æ–ø–æ–ª–Ω—è–µ–º –∏–∑–Ω–∞—á–∞–ª—å–Ω—ã–º —Å–ø–∏—Å–∫–æ–º (–º–∏–Ω—É—Å —É–∂–µ –≤–∑—è—Ç—ã–µ)
      available_fallback = [n for n in all_numbers if n not in result]
      result.extend(random.sample(available_fallback, remaining))
    else:
      result.extend(random.sample(available, remaining))

  return result[:count]


def _generate_balanced(hot_numbers, cold_numbers, all_numbers, count):
  """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∫–æ–º–±–∏–Ω–∞—Ü–∏—é."""
  result = []
  available = list(all_numbers)

  # 1-2 –≥–æ—Ä—è—á–∏—Ö —á–∏—Å–ª–∞
  hot_available = [n for n in hot_numbers if n in available]
  if hot_available and len(result) < count:
    num_hot = random.randint(1, min(2, len(hot_available), count - len(result)))
    selected_hot = random.sample(hot_available, num_hot)
    result.extend(selected_hot)
    for n in selected_hot:
      available.remove(n)

  # 1-2 —Ö–æ–ª–æ–¥–Ω—ã—Ö —á–∏—Å–ª–∞
  cold_available = [n for n in cold_numbers if n in available]
  if cold_available and len(result) < count:
    num_cold = random.randint(1, min(2, len(cold_available), count - len(result)))
    selected_cold = random.sample(cold_available, num_cold)
    result.extend(selected_cold)
    for n in selected_cold:
      available.remove(n)

  # –î–æ–ø–æ–ª–Ω—è–µ–º –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–º–∏ —á–∏—Å–ª–∞–º–∏
  remaining = count - len(result)
  if remaining > 0 and available:
    result.extend(random.sample(available, remaining))

  # –ï—Å–ª–∏ –ø–æ—Å–ª–µ –≤—Å–µ—Ö —à–∞–≥–æ–≤ –Ω–µ –Ω–∞–±—Ä–∞–ª–æ—Å—å –Ω—É–∂–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
  while len(result) < count:
    fallback_available = [n for n in all_numbers if n not in result]
    if not fallback_available: break
    result.append(random.choice(fallback_available))

  return result[:count]


def _generate_with_correlations(frequent_pairs, all_numbers, count):
  """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ–º–±–∏–Ω–∞—Ü–∏—é –∏—Å–ø–æ–ª—å–∑—É—è —á–∞—Å—Ç—ã–µ –ø–∞—Ä—ã."""
  result = []
  available = list(all_numbers)

  if frequent_pairs:
    # –í—ã–±–∏—Ä–∞–µ–º 1-2 —á–∞—Å—Ç—ã–µ –ø–∞—Ä—ã
    num_pairs_to_try = random.randint(1, min(2, len(frequent_pairs)))
    selected_pairs = random.sample(frequent_pairs[:10], num_pairs_to_try)

    for pair_data in selected_pairs:
      pair = pair_data[0]
      if len(result) + 2 <= count:
        if pair[0] in available and pair[1] in available:
          result.extend(pair)
          available.remove(pair[0])
          available.remove(pair[1])

  # –î–æ–ø–æ–ª–Ω—è–µ–º —Å–ª—É—á–∞–π–Ω—ã–º–∏
  remaining = count - len(result)
  if remaining > 0 and available:
    if len(available) >= remaining:
      result.extend(random.sample(available, remaining))
    else:  # –ï—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç, –±–µ—Ä–µ–º —á—Ç–æ –µ—Å—Ç—å –∏ –¥–æ–ø–æ–ª–Ω—è–µ–º
      result.extend(available)
      needed = count - len(result)
      fallback_available = [n for n in all_numbers if n not in result]
      result.extend(random.sample(fallback_available, needed))

  return result[:count]


def generate_multi_strategy_combinations(df_history, num_per_strategy=10):
  """
  –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –∏—Å–ø–æ–ª—å–∑—É—è –≤—Å–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏.

  Args:
      df_history: DataFrame —Å –∏—Å—Ç–æ—Ä–∏–µ–π
      num_per_strategy: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –Ω–∞ –∫–∞–∂–¥—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é

  Returns:
      list: –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∫–æ–º–±–∏–Ω–∞—Ü–∏–π
  """
  all_combinations = []

  # 1. RF-—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ (–ª—É—á—à–∏–µ –ø–æ ML)
  rf_combos = generate_rf_ranked_combinations(df_history, num_per_strategy, num_candidates_to_score=500)
  all_combinations.extend(rf_combos)

  # 2. –ü–∞—Ç—Ç–µ—Ä–Ω-based —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
  strategies = ['hot', 'cold', 'balanced', 'correlated', 'overdue']
  for strategy in strategies:
    pattern_combos = generate_pattern_based_combinations(
      df_history,
      num_per_strategy // len(strategies),
      strategy
    )
    all_combinations.extend(pattern_combos)

  # 3. –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã (–µ—Å–ª–∏ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ —Å–æ–≤–ø–∞–¥–∞—é—Ç)
  unique_combinations = []
  seen = set()

  for f1, f2, desc in all_combinations:
    combo_key = (tuple(sorted(f1)), tuple(sorted(f2)))
    if combo_key not in seen:
      seen.add(combo_key)
      unique_combinations.append((f1, f2, desc))

  # 4. –§–∏–Ω–∞–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –æ—Ü–µ–Ω–∏–≤–∞–µ–º –≤—Å–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ RF
  if GLOBAL_RF_MODEL.is_trained and not df_history.empty:
    scored_combos = []
    for f1, f2, desc in unique_combinations:
      score = GLOBAL_RF_MODEL.score_combination(sorted(f1), sorted(f2), df_history)
      scored_combos.append((f1, f2, desc, score))

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å–∫–æ—Ä—É
    scored_combos.sort(key=lambda x: x[3], reverse=True)

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø-20 —Å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–º–∏ –æ–ø–∏—Å–∞–Ω–∏—è–º–∏
    final_combos = []
    for i, (f1, f2, desc, score) in enumerate(scored_combos[:20]):
      new_desc = f"#{i + 1} {desc} (—Å–∫–æ—Ä: {score:.2f})"
      final_combos.append((f1, f2, new_desc))

    return final_combos

  # if GLOBAL_RF_MODEL.is_trained and not df_history.empty:
  #   last_draw = df_history.iloc[0]
  #   last_f1 = last_draw.get('–ß–∏—Å–ª–∞_–ü–æ–ª–µ1_list')
  #   last_f2 = last_draw.get('–ß–∏—Å–ª–∞_–ü–æ–ª–µ2_list')
  #
  #   if isinstance(last_f1, list) and len(last_f1) == 4 and isinstance(last_f2, list) and len(last_f2) == 4:
  #     scoring_features = np.array(sorted(last_f1) + sorted(last_f2)).reshape(1, -1)
  #
  #     scored_combos = []
  #     for f1, f2, desc in unique_combinations:
  #       score = GLOBAL_RF_MODEL.score_combination(sorted(f1), sorted(f2), scoring_features)
  #       scored_combos.append((f1, f2, desc, score))
  #
  #     # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å–∫–æ—Ä—É
  #     scored_combos.sort(key=lambda x: x[3], reverse=True)
  #
  #     # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø-20 —Å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–º–∏ –æ–ø–∏—Å–∞–Ω–∏—è–º–∏
  #     final_combos = []
  #     for i, (f1, f2, desc, score) in enumerate(scored_combos[:20]):
  #       new_desc = f"#{i + 1} {desc} (—Å–∫–æ—Ä: {score:.2f})"
  #       final_combos.append((f1, f2, new_desc))
  #
  #     return final_combos

  # –ï—Å–ª–∏ RF –Ω–µ –≥–æ—Ç–æ–≤, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤—ã–µ 20
  return unique_combinations[:20]

def record_rf_performance(rf_score: float, combination_count: int, lottery_type: str):
    """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å RF –º–æ–¥–µ–ª–∏"""
    try:
      from backend.app.core.database import get_db
      from backend.app.api.dashboard import DashboardService

      db = next(get_db())
      dashboard_service = DashboardService(db)

      dashboard_service.update_model_statistics(
        lottery_type=lottery_type,
        model_type='rf',
        accuracy=75.0,  # –ú–æ–∂–Ω–æ –≤—ã—á–∏—Å–ª—è—Ç—å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏
        best_score=rf_score,
        predictions_count=combination_count,
        correct_predictions=0  # –û–±–Ω–æ–≤–∏—Ç—Å—è –ø–æ—Å–ª–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
      )

    except Exception as e:
      print(f"–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ RF: {e}")