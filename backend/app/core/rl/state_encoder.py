"""
–ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏–π –¥–ª—è RL
–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –º–µ–∂–¥—É —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è–º–∏ —Å–æ—Å—Ç–æ—è–Ω–∏–π
"""

import numpy as np
import pandas as pd
from typing import List, Dict, Tuple, Optional
from sklearn.preprocessing import StandardScaler
import hashlib
import json
import logging

logger = logging.getLogger(__name__)


class StateEncoder:
  """
  –ö–æ–¥–∏—Ä–æ–≤—â–∏–∫ —Å–æ—Å—Ç–æ—è–Ω–∏–π –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
  """

  def __init__(self, feature_dims: Dict[str, int], use_normalization: bool = True):
    """
    Args:
        feature_dims: –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ {'feature_name': max_value}
        use_normalization: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é
    """
    self.feature_dims = feature_dims
    self.use_normalization = use_normalization

    # –î–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
    self.scaler = StandardScaler() if use_normalization else None
    self.is_fitted = False

    # –î–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏—è –¥–ª—è Q-—Ç–∞–±–ª–∏—Ü—ã
    self.discretization_bins = {
      'universe_length': 10,
      'parity_ratio': 5,
      'mean_gap': 10,
      'mean_frequency': 5,
      'hot_numbers_count': 5,
      'cold_numbers_count': 5,
      'sum_trend': 5,
      'diversity_index': 5
    }

    # –ö—ç—à –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–π
    self._encoding_cache = {}

    logger.info(f"‚úÖ StateEncoder –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å {len(feature_dims)} –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏")

  def encode_continuous(self, state_dict: Dict) -> np.ndarray:
    """
    –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–π –≤–µ–∫—Ç–æ—Ä –¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π

    Args:
        state_dict: –°–ª–æ–≤–∞—Ä—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–æ—Å—Ç–æ—è–Ω–∏—è

    Returns:
        –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –≤–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    """
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –≤–µ–∫—Ç–æ—Ä
    vector = []
    for feature_name in self.feature_dims.keys():
      if feature_name in state_dict:
        value = state_dict[feature_name]
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤ [0, 1]
        max_val = self.feature_dims[feature_name]
        normalized = value / max_val if max_val > 0 else 0
        vector.append(normalized)
      else:
        vector.append(0.0)

    vector = np.array(vector, dtype=np.float32)

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if self.use_normalization and self.scaler:
      if not self.is_fitted:
        # –î–ª—è –ø–µ—Ä–≤–æ–≥–æ –≤—ã–∑–æ–≤–∞ –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
        return vector
      vector = self.scaler.transform(vector.reshape(1, -1))[0]

    return vector

  def encode_discrete(self, state_dict: Dict) -> str:
    """
    –î–∏—Å–∫—Ä–µ—Ç–Ω–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è Q-—Ç–∞–±–ª–∏—Ü—ã

    Args:
        state_dict: –°–ª–æ–≤–∞—Ä—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–æ—Å—Ç–æ—è–Ω–∏—è

    Returns:
        –°—Ç—Ä–æ–∫–æ–≤—ã–π –∫–ª—é—á –¥–ª—è Q-—Ç–∞–±–ª–∏—Ü—ã
    """
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
    state_str = json.dumps(state_dict, sort_keys=True)
    if state_str in self._encoding_cache:
      return self._encoding_cache[state_str]

    # –î–∏—Å–∫—Ä–µ—Ç–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π –ø—Ä–∏–∑–Ω–∞–∫
    discrete_values = []

    for feature_name, num_bins in self.discretization_bins.items():
      if feature_name in state_dict:
        value = state_dict[feature_name]
        max_val = self.feature_dims.get(feature_name, 100)

        # –í—ã—á–∏—Å–ª—è–µ–º –±–∏–Ω
        normalized = value / max_val if max_val > 0 else 0
        bin_idx = min(int(normalized * num_bins), num_bins - 1)
        discrete_values.append(f"{feature_name}:{bin_idx}")

    # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á
    key = "|".join(discrete_values)

    # –ö—ç—à–∏—Ä—É–µ–º
    self._encoding_cache[state_str] = key

    return key

  def encode_hash(self, state_dict: Dict) -> str:
    """
    –•—ç—à-–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –∫–æ–º–ø–∞–∫—Ç–Ω–æ–≥–æ —Ö—Ä–∞–Ω–µ–Ω–∏—è

    Args:
        state_dict: –°–ª–æ–≤–∞—Ä—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–æ—Å—Ç–æ—è–Ω–∏—è

    Returns:
        –•—ç—à —Å–æ—Å—Ç–æ—è–Ω–∏—è
    """
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
    sorted_items = sorted(state_dict.items())
    state_str = json.dumps(sorted_items)

    # –í—ã—á–∏—Å–ª—è–µ–º —Ö—ç—à
    hash_obj = hashlib.md5(state_str.encode())
    return hash_obj.hexdigest()[:16]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 16 —Å–∏–º–≤–æ–ª–æ–≤

  def decode_discrete(self, encoded_state: str) -> Dict:
    """
    –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∏—Å–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –æ–±—Ä–∞—Ç–Ω–æ –≤ —Å–ª–æ–≤–∞—Ä—å

    Args:
        encoded_state: –ó–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞

    Returns:
        –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    """
    state_dict = {}

    parts = encoded_state.split("|")
    for part in parts:
      if ":" in part:
        feature_name, bin_idx = part.split(":")
        bin_idx = int(bin_idx)

        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        if feature_name in self.discretization_bins:
          num_bins = self.discretization_bins[feature_name]
          max_val = self.feature_dims.get(feature_name, 100)

          # –¶–µ–Ω—Ç—Ä –±–∏–Ω–∞
          normalized = (bin_idx + 0.5) / num_bins
          value = normalized * max_val
          state_dict[feature_name] = value

    return state_dict

  def fit(self, states: List[Dict]):
    """
    –û–±—É—á–µ–Ω–∏–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –Ω–∞ –Ω–∞–±–æ—Ä–µ —Å–æ—Å—Ç–æ—è–Ω–∏–π

    Args:
        states: –°–ø–∏—Å–æ–∫ —Å–æ—Å—Ç–æ—è–Ω–∏–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    """
    if not self.use_normalization or not self.scaler:
      return

    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –≤–µ–∫—Ç–æ—Ä—ã
    vectors = []
    for state_dict in states:
      vector = self.encode_continuous(state_dict)
      vectors.append(vector)

    if vectors:
      vectors = np.array(vectors)
      self.scaler.fit(vectors)
      self.is_fitted = True
      logger.info(f"üìä Scaler –æ–±—É—á–µ–Ω –Ω–∞ {len(vectors)} —Å–æ—Å—Ç–æ—è–Ω–∏—è—Ö")

  def get_feature_importance(self, state_dict: Dict) -> Dict[str, float]:
    """
    –û—Ü–µ–Ω–∫–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏

    Args:
        state_dict: –°–ª–æ–≤–∞—Ä—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –≤–∞–∂–Ω–æ—Å—Ç—å—é –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞
    """
    importance = {}

    for feature_name, value in state_dict.items():
      if feature_name in self.feature_dims:
        max_val = self.feature_dims[feature_name]
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ
        normalized = value / max_val if max_val > 0 else 0
        deviation = abs(normalized - 0.5) * 2  # [0, 1]
        importance[feature_name] = deviation

    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–∞–∂–Ω–æ—Å—Ç–∏
    total = sum(importance.values())
    if total > 0:
      for key in importance:
        importance[key] /= total

    return importance


class ActionEncoder:
  """
  –ö–æ–¥–∏—Ä–æ–≤—â–∏–∫ –¥–µ–π—Å—Ç–≤–∏–π (–∫–æ–º–±–∏–Ω–∞—Ü–∏–π —á–∏—Å–µ–ª)
  """

  def __init__(self, lottery_config: Dict):
    """
    Args:
        lottery_config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ª–æ—Ç–µ—Ä–µ–∏
    """
    self.lottery_config = lottery_config
    self.field1_size = lottery_config['field1_size']
    self.field2_size = lottery_config['field2_size']
    self.field1_max = lottery_config['field1_max']
    self.field2_max = lottery_config['field2_max']

    # –ö—ç—à –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞
    self._action_cache = {}
    self._index_cache = {}

    logger.info(f"‚úÖ ActionEncoder –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è –ª–æ—Ç–µ—Ä–µ–∏ {self.field1_size}/{self.field1_max}")

  def encode(self, field1: List[int], field2: List[int]) -> str:
    """
    –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—è –≤ —Å—Ç—Ä–æ–∫—É

    Args:
        field1: –ß–∏—Å–ª–∞ –ø–µ—Ä–≤–æ–≥–æ –ø–æ–ª—è
        field2: –ß–∏—Å–ª–∞ –≤—Ç–æ—Ä–æ–≥–æ –ø–æ–ª—è

    Returns:
        –ó–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ
    """
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
    f1_sorted = sorted(field1)
    f2_sorted = sorted(field2)

    # –°–æ–∑–¥–∞–µ–º –∫–ª—é—á
    key = f"F1:{','.join(map(str, f1_sorted))}|F2:{','.join(map(str, f2_sorted))}"
    return key

  def decode(self, encoded_action: str) -> Tuple[List[int], List[int]]:
    """
    –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—è –∏–∑ —Å—Ç—Ä–æ–∫–∏

    Args:
        encoded_action: –ó–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ

    Returns:
        (field1, field2)
    """
    parts = encoded_action.split("|")

    field1 = []
    field2 = []

    for part in parts:
      if part.startswith("F1:"):
        numbers = part[3:].split(",")
        field1 = [int(n) for n in numbers if n]
      elif part.startswith("F2:"):
        numbers = part[3:].split(",")
        field2 = [int(n) for n in numbers if n]

    return field1, field2

  def action_to_index(self, field1: List[int], field2: List[int]) -> int:
    """
    –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—è –≤ –∏–Ω–¥–µ–∫—Å (–¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π)

    –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ö—ç—à
    """
    action_str = self.encode(field1, field2)

    if action_str in self._index_cache:
      return self._index_cache[action_str]

    # –ü—Ä–æ—Å—Ç–æ–π —Ö—ç—à –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ
    hash_val = hash(action_str)
    index = abs(hash_val) % 1000000  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –º–∏–ª–ª–∏–æ–Ω–æ–º

    self._index_cache[action_str] = index
    return index

  def index_to_action(self, index: int) -> Optional[Tuple[List[int], List[int]]]:
    """
    –û–±—Ä–∞—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –≤ –¥–µ–π—Å—Ç–≤–∏–µ

    –¢—Ä–µ–±—É–µ—Ç –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
    """
    # –ò—â–µ–º –≤ –∫—ç—à–µ
    for action_str, cached_idx in self._index_cache.items():
      if cached_idx == index:
        return self.decode(action_str)

    # –ù–µ –Ω–∞–π–¥–µ–Ω–æ - –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω–æ–µ
    import random
    field1 = sorted(random.sample(range(1, self.field1_max + 1), self.field1_size))
    field2 = sorted(random.sample(range(1, self.field2_max + 1), self.field2_size))

    return field1, field2

  def sample_random_action(self) -> Tuple[List[int], List[int]]:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è"""
    import random
    field1 = sorted(random.sample(range(1, self.field1_max + 1), self.field1_size))
    field2 = sorted(random.sample(range(1, self.field2_max + 1), self.field2_size))
    return field1, field2