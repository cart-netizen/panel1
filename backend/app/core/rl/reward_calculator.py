"""
–†–∞—Å—á–µ—Ç –Ω–∞–≥—Ä–∞–¥ –¥–ª—è RL –∞–≥–µ–Ω—Ç–∞
–†–∞–∑–ª–∏—á–Ω—ã–µ —Å—Ö–µ–º—ã –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
"""

import numpy as np
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass
import logging

logger = logging.getLogger(__name__)


@dataclass
class RewardScheme:
  """–°—Ö–µ–º–∞ –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è"""
  name: str
  ticket_cost: float = 1.0

  # –ù–∞–≥—Ä–∞–¥—ã –∑–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –≤ –ø–æ–ª–µ 1
  match_2_f1: float = 2.0
  match_3_f1: float = 10.0
  match_4_f1: float = 100.0
  match_5_f1: float = 1000.0
  jackpot_f1: float = 10000.0

  # –ù–∞–≥—Ä–∞–¥—ã –∑–∞ –ø–æ–ª–µ 2
  match_1_f2: float = 5.0
  match_all_f2: float = 50.0
  super_jackpot: float = 100000.0

  # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –±–æ–Ω—É—Å—ã
  hot_number_bonus: float = 0.1
  cold_number_penalty: float = -0.05
  diversity_bonus: float = 0.2
  pattern_bonus: float = 0.5


class RewardCalculator:
  """
  –ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä –Ω–∞–≥—Ä–∞–¥ –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å—Ö–µ–º –ª–æ—Ç–µ—Ä–µ–∏
  """

  def __init__(self, lottery_config: Dict, scheme: Optional[RewardScheme] = None):
    """
    Args:
        lottery_config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ª–æ—Ç–µ—Ä–µ–∏
        scheme: –°—Ö–µ–º–∞ –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è
    """
    self.lottery_config = lottery_config
    self.scheme = scheme or RewardScheme(name="default")

    self.field1_size = lottery_config['field1_size']
    self.field2_size = lottery_config['field2_size']

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–∞–≥—Ä–∞–¥
    self.reward_history = []
    self.total_rewards = 0
    self.total_tickets = 0

    logger.info(f"‚úÖ RewardCalculator –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å–æ —Å—Ö–µ–º–æ–π '{self.scheme.name}'")

  def calculate(self,
                predicted_f1: List[int],
                predicted_f2: List[int],
                actual_f1: List[int],
                actual_f2: List[int],
                state_features: Optional[Dict] = None) -> float:
    """
    –†–∞—Å—á–µ—Ç –Ω–∞–≥—Ä–∞–¥—ã –∑–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ

    Args:
        predicted_f1: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ —á–∏—Å–ª–∞ –ø–æ–ª—è 1
        predicted_f2: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ —á–∏—Å–ª–∞ –ø–æ–ª—è 2
        actual_f1: –§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —á–∏—Å–ª–∞ –ø–æ–ª—è 1
        actual_f2: –§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —á–∏—Å–ª–∞ –ø–æ–ª—è 2
        state_features: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è

    Returns:
        –ù–∞–≥—Ä–∞–¥–∞ (–º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–π)
    """
    # –ë–∞–∑–æ–≤–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –±–∏–ª–µ—Ç–∞ (–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–∞—è)
    reward = -self.scheme.ticket_cost

    # –ü–æ–¥—Å—á–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
    matches_f1 = len(set(predicted_f1) & set(actual_f1))
    matches_f2 = len(set(predicted_f2) & set(actual_f2))

    # –ù–∞–≥—Ä–∞–¥—ã –∑–∞ –ø–æ–ª–µ 1
    if matches_f1 >= 2:
      reward += self.scheme.match_2_f1
    if matches_f1 >= 3:
      reward += self.scheme.match_3_f1
    if matches_f1 >= 4:
      reward += self.scheme.match_4_f1
    if matches_f1 >= 5:
      reward += self.scheme.match_5_f1
    if matches_f1 == self.field1_size:
      reward += self.scheme.jackpot_f1
      logger.info(f"üéØ –î–ñ–ï–ö–ü–û–¢ –≤ –ø–æ–ª–µ 1! –°–æ–≤–ø–∞–¥–µ–Ω–∏–π: {matches_f1}")

    # –ù–∞–≥—Ä–∞–¥—ã –∑–∞ –ø–æ–ª–µ 2
    if matches_f2 >= 1 and matches_f1 >= 2:
      reward += self.scheme.match_1_f2
    if matches_f2 == self.field2_size and matches_f1 >= 3:
      reward += self.scheme.match_all_f2
    if matches_f2 == self.field2_size and matches_f1 == self.field1_size:
      reward += self.scheme.super_jackpot
      logger.info(f"üíé –°–£–ü–ï–†-–î–ñ–ï–ö–ü–û–¢! –ü–æ–ª–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ!")

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –±–æ–Ω—É—Å—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–æ—Å—Ç–æ—è–Ω–∏—è
    if state_features:
      reward = self._apply_feature_bonuses(reward, predicted_f1, predicted_f2, state_features)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    self.reward_history.append(reward)
    self.total_rewards += reward
    self.total_tickets += 1

    return reward

  def _apply_feature_bonuses(self, base_reward: float,
                             predicted_f1: List[int],
                             predicted_f2: List[int],
                             state_features: Dict) -> float:
    """
    –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –±–æ–Ω—É—Å–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

    Args:
        base_reward: –ë–∞–∑–æ–≤–∞—è –Ω–∞–≥—Ä–∞–¥–∞
        predicted_f1: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ —á–∏—Å–ª–∞ –ø–æ–ª—è 1
        predicted_f2: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ —á–∏—Å–ª–∞ –ø–æ–ª—è 2
        state_features: –ü—Ä–∏–∑–Ω–∞–∫–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è

    Returns:
        –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –Ω–∞–≥—Ä–∞–¥–∞
    """
    reward = base_reward

    # –ë–æ–Ω—É—Å –∑–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≥–æ—Ä—è—á–∏—Ö —á–∏—Å–µ–ª
    if 'hot_numbers' in state_features:
      hot_numbers = state_features['hot_numbers']
      hot_count = len(set(predicted_f1) & set(hot_numbers))
      reward += hot_count * self.scheme.hot_number_bonus

    # –®—Ç—Ä–∞—Ñ –∑–∞ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Ö–æ–ª–æ–¥–Ω—ã—Ö —á–∏—Å–µ–ª
    if 'cold_numbers' in state_features:
      cold_numbers = state_features['cold_numbers']
      cold_count = len(set(predicted_f1) & set(cold_numbers))
      if cold_count > self.field1_size // 2:
        reward += cold_count * self.scheme.cold_number_penalty

    # –ë–æ–Ω—É—Å –∑–∞ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ
    if 'diversity_index' in state_features:
      diversity = state_features['diversity_index']
      if diversity > 0.7:
        reward += self.scheme.diversity_bonus

    # –ë–æ–Ω—É—Å –∑–∞ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
    if self._check_patterns(predicted_f1):
      reward += self.scheme.pattern_bonus

    return reward

  def _check_patterns(self, numbers: List[int]) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤ —á–∏—Å–ª–∞—Ö

    Args:
        numbers: –°–ø–∏—Å–æ–∫ —á–∏—Å–µ–ª

    Returns:
        True –µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω
    """
    if len(numbers) < 3:
      return False

    sorted_nums = sorted(numbers)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∞—Ä–∏—Ñ–º–µ—Ç–∏—á–µ—Å–∫—É—é –ø—Ä–æ–≥—Ä–µ—Å—Å–∏—é
    diffs = [sorted_nums[i + 1] - sorted_nums[i] for i in range(len(sorted_nums) - 1)]
    if len(set(diffs)) == 1:  # –í—Å–µ —Ä–∞–∑–Ω–æ—Å—Ç–∏ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ
      return True

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ —á–∏—Å–ª–∞
    consecutive_count = 1
    for i in range(len(sorted_nums) - 1):
      if sorted_nums[i + 1] - sorted_nums[i] == 1:
        consecutive_count += 1
        if consecutive_count >= 3:
          return True
      else:
        consecutive_count = 1

    return False

  def calculate_expected_value(self, num_simulations: int = 10000) -> float:
    """
    –†–∞—Å—á–µ—Ç –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–∂–∏–¥–∞–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏–∏

    Args:
        num_simulations: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º—É–ª—è—Ü–∏–π

    Returns:
        –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ
    """
    if not self.reward_history:
      return -self.scheme.ticket_cost

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–∞–≥—Ä–∞–¥—ã –¥–ª—è –æ—Ü–µ–Ω–∫–∏
    recent_rewards = self.reward_history[-min(num_simulations, len(self.reward_history)):]
    return np.mean(recent_rewards)

  def get_statistics(self) -> Dict:
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –Ω–∞–≥—Ä–∞–¥

    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
    """
    if not self.reward_history:
      return {
        'total_tickets': 0,
        'total_rewards': 0,
        'average_reward': 0,
        'max_reward': 0,
        'min_reward': 0,
        'roi': 0,
        'win_rate': 0
      }

    rewards = np.array(self.reward_history)
    wins = rewards > 0

    return {
      'total_tickets': self.total_tickets,
      'total_rewards': self.total_rewards,
      'average_reward': np.mean(rewards),
      'max_reward': np.max(rewards),
      'min_reward': np.min(rewards),
      'std_reward': np.std(rewards),
      'roi': (self.total_rewards / (
            self.total_tickets * self.scheme.ticket_cost)) * 100 if self.total_tickets > 0 else 0,
      'win_rate': np.mean(wins) * 100,
      'expected_value': self.calculate_expected_value()
    }

  def reset_statistics(self):
    """–°–±—Ä–æ—Å –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
    self.reward_history = []
    self.total_rewards = 0
    self.total_tickets = 0
    logger.info("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–∞–≥—Ä–∞–¥ —Å–±—Ä–æ—à–µ–Ω–∞")


class ShapedRewardCalculator(RewardCalculator):
  """
  –ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä —Å reward shaping –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è
  """

  def __init__(self, lottery_config: Dict):
    super().__init__(lottery_config)
    self.scheme.name = "shaped"

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è shaping
    self.proximity_weight = 0.01  # –í–µ—Å –∑–∞ –±–ª–∏–∑–æ—Å—Ç—å –∫ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —á–∏—Å–ª–∞–º
    self.improvement_weight = 0.05  # –í–µ—Å –∑–∞ —É–ª—É—á—à–µ–Ω–∏–µ
    self.previous_matches = 0

  def calculate(self,
                predicted_f1: List[int],
                predicted_f2: List[int],
                actual_f1: List[int],
                actual_f2: List[int],
                state_features: Optional[Dict] = None) -> float:
    """
    –†–∞—Å—á–µ—Ç shaped –Ω–∞–≥—Ä–∞–¥—ã —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ —Å–∏–≥–Ω–∞–ª–∞–º–∏
    """
    # –ë–∞–∑–æ–≤–∞—è –Ω–∞–≥—Ä–∞–¥–∞
    base_reward = super().calculate(predicted_f1, predicted_f2, actual_f1, actual_f2, state_features)

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π shaping
    shaped_reward = base_reward

    # –ù–∞–≥—Ä–∞–¥–∞ –∑–∞ –±–ª–∏–∑–æ—Å—Ç—å –∫ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —á–∏—Å–ª–∞–º
    proximity_bonus = self._calculate_proximity_bonus(predicted_f1, actual_f1)
    shaped_reward += proximity_bonus * self.proximity_weight

    # –ù–∞–≥—Ä–∞–¥–∞ –∑–∞ —É–ª—É—á—à–µ–Ω–∏–µ
    current_matches = len(set(predicted_f1) & set(actual_f1))
    if current_matches > self.previous_matches:
      shaped_reward += (current_matches - self.previous_matches) * self.improvement_weight
    self.previous_matches = current_matches

    return shaped_reward

  def _calculate_proximity_bonus(self, predicted: List[int], actual: List[int]) -> float:
    """
    –ë–æ–Ω—É—Å –∑–∞ –±–ª–∏–∑–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö —á–∏—Å–µ–ª –∫ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–º
    """
    proximity_sum = 0

    for pred_num in predicted:
      # –ù–∞—Ö–æ–¥–∏–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ –ª—é–±–æ–≥–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —á–∏—Å–ª–∞
      min_distance = min(abs(pred_num - act_num) for act_num in actual)
      # –ò–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –≤ –±–æ–Ω—É—Å
      proximity_sum += 1.0 / (1.0 + min_distance)

    return proximity_sum